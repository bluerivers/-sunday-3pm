{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is z-score that value minus mean divided by standard deviation\n",
    "# http://duramecho.com/Misc/WhyMinusOneInSd.html\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    f = np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1]\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep=',', header=None)\n",
    "    return df\n",
    "\n",
    "def merge_column(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(df.shape[1]/2):\n",
    "        new_df[i] = df[i] * df[i+1]\n",
    "    return new_df\n",
    "\n",
    "# https://stackoverflow.com/a/42523230\n",
    "def one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        del df[each]\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       10  0_1  0_2  0_3  0_4  1_1  1_2  1_3  1_4  1_5  ...   9_4  9_5  9_6  \\\n",
      "25005   0    0    0    1    0    0    0    0    0    0  ...     1    0    0   \n",
      "25006   1    0    0    0    1    1    0    0    0    0  ...     0    0    0   \n",
      "25007   1    0    1    0    0    1    0    0    0    0  ...     0    0    0   \n",
      "25008   1    0    1    0    0    0    0    0    0    0  ...     0    0    0   \n",
      "25009   1    1    0    0    0    0    0    0    0    0  ...     0    0    0   \n",
      "\n",
      "       9_7  9_8  9_9  9_10  9_11  9_12  9_13  \n",
      "25005    0    0    0     0     0     0     0  \n",
      "25006    0    0    0     1     0     0     0  \n",
      "25007    0    0    0     0     0     0     1  \n",
      "25008    0    0    1     0     0     0     0  \n",
      "25009    1    0    0     0     0     0     0  \n",
      "\n",
      "[5 rows x 86 columns]\n",
      "        10  0_1  0_2  0_3  0_4  1_1  1_2  1_3  1_4  1_5  ...   9_4  9_5  9_6  \\\n",
      "999995   1    0    0    1    0    1    0    0    0    0  ...     0    0    1   \n",
      "999996   1    0    0    1    0    0    0    1    0    0  ...     0    0    0   \n",
      "999997   1    1    0    0    0    0    0    0    0    0  ...     0    0    0   \n",
      "999998   1    0    0    1    0    0    0    0    0    0  ...     0    0    0   \n",
      "999999   2    0    1    0    0    0    0    0    0    1  ...     0    0    0   \n",
      "\n",
      "        9_7  9_8  9_9  9_10  9_11  9_12  9_13  \n",
      "999995    0    0    0     0     0     0     0  \n",
      "999996    0    0    0     0     0     0     0  \n",
      "999997    1    0    0     0     0     0     0  \n",
      "999998    0    1    0     0     0     0     0  \n",
      "999999    0    0    0     0     0     0     0  \n",
      "\n",
      "[5 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "df = read_data('poker-hand-training-true.data')\n",
    "df_test = read_data('poker-hand-testing.data')\n",
    "# df.tail()\n",
    "# df_test.tail()\n",
    "df = one_hot(df, df.iloc[:,:-1].columns)\n",
    "df_test = one_hot(df_test, df_test.iloc[:,:-1].columns)\n",
    "print(df.tail())\n",
    "print(df_test.tail())\n",
    "# df[10] = df[10] - 1\n",
    "# df_test[10] = df_test[10] - 1\n",
    "# print(df.tail())\n",
    "# print(df_test.tail())\n",
    "# df[10].value_counts().sort_index().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18544144  0.18841386  0.18745751  0.18869141  0.07297093  0.07158867\n",
      "  0.06959014  0.07084475  0.06992965  0.06884207  0.07226361  0.07182504\n",
      "  0.07246585  0.06942026  0.07108162  0.07155489  0.07070933  0.18863199\n",
      "  0.18733744  0.1855836   0.18845355  0.07307185  0.07091245  0.07060773\n",
      "  0.07037055  0.06833114  0.072095    0.07060773  0.07013321  0.06942026\n",
      "  0.07094629  0.07125072  0.0715211   0.07381113  0.18705685  0.18661465\n",
      "  0.18550239  0.19079198  0.07003145  0.07053998  0.07239845  0.07138594\n",
      "  0.0708786   0.06965806  0.07111545  0.07060773  0.06856966  0.07357607\n",
      "  0.0706416   0.07313913  0.07053998  0.18783694  0.1874175   0.18873101\n",
      "  0.18602939  0.07300457  0.07313913  0.07354248  0.07026885  0.0696241\n",
      "  0.0706416   0.07165622  0.06901222  0.07175752  0.07101396  0.07199379\n",
      "  0.06809246  0.06931829  0.18861217  0.18588772  0.18873101  0.18677563\n",
      "  0.07256692  0.07212873  0.07067547  0.07175752  0.07233104  0.06999752\n",
      "  0.06792188  0.07337447  0.07125072  0.07182504  0.07037055  0.06894417\n",
      "  0.06992965]\n",
      "(25010, 85) (25010, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, 1:].values\n",
    "labels = df.iloc[:, :1].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "features_test = df_test.iloc[:, 1:].values\n",
    "labels_test = df_test.iloc[:, :1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 1\n"
     ]
    }
   ],
   "source": [
    "train_x = features\n",
    "train_y = labels\n",
    "test_x = features_test\n",
    "test_y = labels_test\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot_22:0\", shape=(?, 1, 10), dtype=float32)\n",
      "reshape Tensor(\"Reshape_44:0\", shape=(?, 10), dtype=float32)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 2000\n",
    "learning_rate = 0.001\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 10\n",
    "\n",
    "# x는 float32 로 할 필요가 있나? normalized 되었기때문에 float32 써야함 or dropout에서 float를 씀\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(np.array_equal(sess.run(tf.one_hot(train_y, nb_classes)), one_hot(df, df.iloc[:,:1].columns).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1)), tf.Variable(tf.random_normal([shape[1]]))\n",
    "\n",
    "def make_hidden_layer(previous_h, weight, bias, p_keep_hidden):\n",
    "    h = tf.nn.relu(tf.matmul(previous_h, weight) + bias)\n",
    "    h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    return h\n",
    "\n",
    "def model(X, p_keep_input, p_keep_hidden): # this network is the same as the previous one except with an extra hidden layer + dropout\n",
    "    s_1 = feature_count + 2\n",
    "    s_2 = feature_count + 2\n",
    "    s_3 = feature_count\n",
    "#     s_4 = feature_count\n",
    "    \n",
    "    w_h, b = init_weights([feature_count, s_1])\n",
    "    w_h2, b2 = init_weights([s_1, s_2])\n",
    "    w_h3, b3 = init_weights([s_2, s_3])\n",
    "#     w_h4, b4 = init_weights([s_3, s_4])\n",
    "    w_o, b_o = init_weights([s_3, nb_classes])\n",
    "    \n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    h = make_hidden_layer(X, w_h, b, p_keep_hidden)\n",
    "    h2 = make_hidden_layer(h, w_h2, b2, p_keep_hidden)\n",
    "    h3 = make_hidden_layer(h2, w_h3, b3, p_keep_hidden)\n",
    "#     h4 = make_hidden_layer(h3, w_h4, b4, p_keep_hidden)\n",
    "    \n",
    "    return tf.matmul(h3, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_keep_input = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 85) (25010, 1)\n",
      "(1000000, 85) (1000000, 1)\n",
      "(?, 85) (?, 1)\n",
      "Step:     0\tLoss: 2.997\tAcc: 1.63%\n",
      "Step:   500\tLoss: 0.339\tAcc: 89.56%\n",
      "Step:  1000\tLoss: 0.237\tAcc: 91.85%\n",
      "Step:  1500\tLoss: 0.204\tAcc: 92.77%\n",
      "Step:  2000\tLoss: 0.182\tAcc: 93.17%\n",
      "(1000000,)\n",
      "Test Accuracy: 0.982166\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_i = 0.95\n",
    "training_dropout_h = 0.95\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 500 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, \n",
    "                                                         p_keep_input: 1.0,\n",
    "                                                         p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2002,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x165099aed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
