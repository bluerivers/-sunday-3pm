{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is z-score that value minus mean divided by standard deviation\n",
    "# http://duramecho.com/Misc/WhyMinusOneInSd.html\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    f = np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1]\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep=',', header=None)\n",
    "    return df\n",
    "\n",
    "def merge_column(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(df.shape[1]/2):\n",
    "        new_df[i] = df[i] * df[i+1]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1   2   3   4   5   6   7   8   9   10\n",
      "25005   3   9   2   6   4  11   4  12   2   4   0\n",
      "25006   4   1   4  10   3  13   3   4   1  10   1\n",
      "25007   2   1   2  10   4   4   4   1   4  13   1\n",
      "25008   2  12   4   3   1  10   1  12   4   9   1\n",
      "25009   1   7   3  11   3   3   4   8   3   7   1\n",
      "        0   1   2   3   4   5   6   7   8   9   10\n",
      "999995   3   1   1  12   2   9   4   9   2   6   1\n",
      "999996   3   3   4   5   2   7   1   4   4   3   1\n",
      "999997   1  11   4   7   3   9   1  13   2   7   1\n",
      "999998   3  11   1   8   1   1   3  13   2   8   1\n",
      "999999   2   5   2   9   4   9   2   3   3   3   2\n"
     ]
    }
   ],
   "source": [
    "df = read_data('poker-hand-training-true.data')\n",
    "df_test = read_data('poker-hand-testing.data')\n",
    "print(df.tail())\n",
    "print(df_test.tail())\n",
    "df = df[df[10] != 0]\n",
    "df_test = df_test[df_test[10] != 0]\n",
    "# df[df[10].equals(0)].value_counts().sort_index().plot('bar')\n",
    "# df[10].value_counts().sort_index().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23984746  14.09081675   1.25621937  14.21451941   1.26434212\n",
      "  14.04456486   1.23643468  14.09136767   1.24684169  13.99689843]\n",
      "(12517, 10) (12517, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, :-1].values\n",
    "labels = df.iloc[:, -1:].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "features_test = df_test.iloc[:, :-1].values\n",
    "labels_test = df_test.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0000799  1.0000799  1.0000799  1.0000799  1.0000799  1.0000799\n",
      "  1.0000799  1.0000799  1.0000799  1.0000799]\n",
      "[ 1.000002  1.000002  1.000002  1.000002  1.000002  1.000002  1.000002\n",
      "  1.000002  1.000002  1.000002]\n"
     ]
    }
   ],
   "source": [
    "features = feature_normalize(features)\n",
    "print(stats.describe(features).variance)\n",
    "\n",
    "features_test = feature_normalize(features_test)\n",
    "print(stats.describe(features_test).variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1\n"
     ]
    }
   ],
   "source": [
    "train_x = features\n",
    "train_y = labels\n",
    "test_x = features_test\n",
    "test_y = labels_test\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot_4:0\", shape=(?, 1, 10), dtype=float32)\n",
      "reshape Tensor(\"Reshape_16:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 5000\n",
    "learning_rate = 0.1\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 10\n",
    "\n",
    "# x는 float32 로 할 필요가 있나? normalized 되었기때문에 float32 써야함\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1))\n",
    "\n",
    "def model(X, p_keep_input, p_keep_hidden): # this network is the same as the previous one except with an extra hidden layer + dropout\n",
    "    s_1 = feature_count + 4\n",
    "    s_2 = feature_count + 4\n",
    "    \n",
    "    w_h = init_weights([feature_count, s_1])\n",
    "    w_h2 = init_weights([s_1, s_2])\n",
    "    w_o = init_weights([s_2, nb_classes])\n",
    "    \n",
    "    b = tf.Variable(tf.random_normal([s_1]))\n",
    "    b2 = tf.Variable(tf.random_normal([s_2]))\n",
    "    b_o = tf.Variable(tf.random_normal([nb_classes]))\n",
    "    \n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h) + b)\n",
    "    h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    h2 = tf.nn.relu(tf.matmul(h, w_h2) + b2)\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    \n",
    "    \n",
    "    return tf.matmul(h2, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_keep_input = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12517, 10) (12517, 1)\n",
      "(498791, 10) (498791, 1)\n",
      "(?, 10) (?, 1)\n",
      "Step:     0\tLoss: 3.621\tAcc: 0.43%\n",
      "Step:  1000\tLoss: 0.573\tAcc: 84.68%\n",
      "Step:  2000\tLoss: 0.571\tAcc: 84.69%\n",
      "Step:  3000\tLoss: 0.571\tAcc: 84.61%\n",
      "Step:  4000\tLoss: 0.570\tAcc: 84.70%\n",
      "Step:  5000\tLoss: 0.571\tAcc: 84.71%\n",
      "(498791,)\n",
      "Test Accuracy: 0.847044\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_i = 0.8\n",
    "training_dropout_h = 0.7\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, \n",
    "                                                         p_keep_input: 1.0,\n",
    "                                                         p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5002,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ee13b3cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
