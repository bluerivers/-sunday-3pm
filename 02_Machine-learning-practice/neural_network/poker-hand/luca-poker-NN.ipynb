{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is z-score that value minus mean divided by standard deviation\n",
    "# http://duramecho.com/Misc/WhyMinusOneInSd.html\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    f = np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1]\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep=',', header=None)\n",
    "    return df\n",
    "\n",
    "def merge_column(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(df.shape[1]/2):\n",
    "        new_df[i] = df[i] * df[i+1]\n",
    "    return new_df\n",
    "\n",
    "def one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        del df[each]\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       10  0_1  0_2  0_3  0_4  1_1  1_2  1_3  1_4  1_5  ...   9_4  9_5  9_6  \\\n",
      "25005   0    0    0    1    0    0    0    0    0    0  ...     1    0    0   \n",
      "25006   1    0    0    0    1    1    0    0    0    0  ...     0    0    0   \n",
      "25007   1    0    1    0    0    1    0    0    0    0  ...     0    0    0   \n",
      "25008   1    0    1    0    0    0    0    0    0    0  ...     0    0    0   \n",
      "25009   1    1    0    0    0    0    0    0    0    0  ...     0    0    0   \n",
      "\n",
      "       9_7  9_8  9_9  9_10  9_11  9_12  9_13  \n",
      "25005    0    0    0     0     0     0     0  \n",
      "25006    0    0    0     1     0     0     0  \n",
      "25007    0    0    0     0     0     0     1  \n",
      "25008    0    0    1     0     0     0     0  \n",
      "25009    1    0    0     0     0     0     0  \n",
      "\n",
      "[5 rows x 86 columns]\n",
      "        10  0_1  0_2  0_3  0_4  1_1  1_2  1_3  1_4  1_5  ...   9_4  9_5  9_6  \\\n",
      "999995   1    0    0    1    0    1    0    0    0    0  ...     0    0    1   \n",
      "999996   1    0    0    1    0    0    0    1    0    0  ...     0    0    0   \n",
      "999997   1    1    0    0    0    0    0    0    0    0  ...     0    0    0   \n",
      "999998   1    0    0    1    0    0    0    0    0    0  ...     0    0    0   \n",
      "999999   2    0    1    0    0    0    0    0    0    1  ...     0    0    0   \n",
      "\n",
      "        9_7  9_8  9_9  9_10  9_11  9_12  9_13  \n",
      "999995    0    0    0     0     0     0     0  \n",
      "999996    0    0    0     0     0     0     0  \n",
      "999997    1    0    0     0     0     0     0  \n",
      "999998    0    1    0     0     0     0     0  \n",
      "999999    0    0    0     0     0     0     0  \n",
      "\n",
      "[5 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "df = read_data('poker-hand-training-true.data')\n",
    "df_test = read_data('poker-hand-testing.data')\n",
    "\n",
    "df = one_hot(df, df.iloc[:,:-1].columns)\n",
    "df_test = one_hot(df_test, df_test.iloc[:,:-1].columns)\n",
    "print(df.tail())\n",
    "print(df_test.tail())\n",
    "# df[10].value_counts().sort_index().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18544144  0.18841386  0.18745751  0.18869141  0.07297093  0.07158867\n",
      "  0.06959014  0.07084475  0.06992965  0.06884207  0.07226361  0.07182504\n",
      "  0.07246585  0.06942026  0.07108162  0.07155489  0.07070933  0.18863199\n",
      "  0.18733744  0.1855836   0.18845355  0.07307185  0.07091245  0.07060773\n",
      "  0.07037055  0.06833114  0.072095    0.07060773  0.07013321  0.06942026\n",
      "  0.07094629  0.07125072  0.0715211   0.07381113  0.18705685  0.18661465\n",
      "  0.18550239  0.19079198  0.07003145  0.07053998  0.07239845  0.07138594\n",
      "  0.0708786   0.06965806  0.07111545  0.07060773  0.06856966  0.07357607\n",
      "  0.0706416   0.07313913  0.07053998  0.18783694  0.1874175   0.18873101\n",
      "  0.18602939  0.07300457  0.07313913  0.07354248  0.07026885  0.0696241\n",
      "  0.0706416   0.07165622  0.06901222  0.07175752  0.07101396  0.07199379\n",
      "  0.06809246  0.06931829  0.18861217  0.18588772  0.18873101  0.18677563\n",
      "  0.07256692  0.07212873  0.07067547  0.07175752  0.07233104  0.06999752\n",
      "  0.06792188  0.07337447  0.07125072  0.07182504  0.07037055  0.06894417\n",
      "  0.06992965]\n",
      "(25010, 85) (25010, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, 1:].values\n",
    "labels = df.iloc[:, :1].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "features_test = df_test.iloc[:, :-1].values\n",
    "labels_test = df_test.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18544144  0.18841386  0.18745751  0.18869141  0.07297093  0.07158867\n",
      "  0.06959014  0.07084475  0.06992965  0.06884207  0.07226361  0.07182504\n",
      "  0.07246585  0.06942026  0.07108162  0.07155489  0.07070933  0.18863199\n",
      "  0.18733744  0.1855836   0.18845355  0.07307185  0.07091245  0.07060773\n",
      "  0.07037055  0.06833114  0.072095    0.07060773  0.07013321  0.06942026\n",
      "  0.07094629  0.07125072  0.0715211   0.07381113  0.18705685  0.18661465\n",
      "  0.18550239  0.19079198  0.07003145  0.07053998  0.07239845  0.07138594\n",
      "  0.0708786   0.06965806  0.07111545  0.07060773  0.06856966  0.07357607\n",
      "  0.0706416   0.07313913  0.07053998  0.18783694  0.1874175   0.18873101\n",
      "  0.18602939  0.07300457  0.07313913  0.07354248  0.07026885  0.0696241\n",
      "  0.0706416   0.07165622  0.06901222  0.07175752  0.07101396  0.07199379\n",
      "  0.06809246  0.06931829  0.18861217  0.18588772  0.18873101  0.18677563\n",
      "  0.07256692  0.07212873  0.07067547  0.07175752  0.07233104  0.06999752\n",
      "  0.06792188  0.07337447  0.07125072  0.07182504  0.07037055  0.06894417\n",
      "  0.06992965]\n",
      "[ 0.59811252  0.18746868  0.18719882  0.18794938  0.18738263  0.0712842\n",
      "  0.070967    0.0709086   0.07115397  0.070967    0.07130956  0.07071642\n",
      "  0.07093399  0.07059276  0.07097292  0.07126729  0.07100169  0.07100169\n",
      "  0.18768106  0.18730854  0.18739314  0.18761763  0.07086205  0.07096277\n",
      "  0.07116243  0.07074691  0.07061563  0.07108122  0.07117765  0.07108461\n",
      "  0.07063935  0.07079517  0.07138649  0.07132309  0.07123939  0.18755068\n",
      "  0.18701876  0.18787363  0.18755618  0.07121824  0.07112098  0.07069271\n",
      "  0.07091283  0.07102961  0.07081972  0.07150819  0.07106515  0.0706385\n",
      "  0.07113282  0.07103046  0.07095938  0.07094838  0.18724042  0.18764111\n",
      "  0.18779983  0.18731856  0.07084596  0.07114551  0.07085951  0.07097631\n",
      "  0.07091453  0.07071642  0.07156226  0.07083157  0.0711472   0.07093484\n",
      "  0.071022    0.07108376  0.07103723  0.18787712  0.18715271  0.18733608\n",
      "  0.18763362  0.0708485   0.07142791  0.07154959  0.07128589  0.07092214\n",
      "  0.07095854  0.07080194  0.07110998  0.07129857  0.07105077  0.0705038\n",
      "  0.070597  ]\n"
     ]
    }
   ],
   "source": [
    "# features = feature_normalize(features)\n",
    "print(stats.describe(features).variance)\n",
    "\n",
    "# features_test = feature_normalize(features_test)\n",
    "print(stats.describe(features_test).variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 1\n"
     ]
    }
   ],
   "source": [
    "train_x = features\n",
    "train_y = labels\n",
    "test_x = features_test\n",
    "test_y = labels_test\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot_8:0\", shape=(?, 1, 10), dtype=float32)\n",
      "reshape Tensor(\"Reshape_29:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 5000\n",
    "learning_rate = 0.1\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 10\n",
    "\n",
    "# x는 float32 로 할 필요가 있나? normalized 되었기때문에 float32 써야함\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1))\n",
    "\n",
    "def model(X, p_keep_input, p_keep_hidden): # this network is the same as the previous one except with an extra hidden layer + dropout\n",
    "    s_1 = feature_count + 4\n",
    "    s_2 = feature_count + 4\n",
    "    \n",
    "    w_h = init_weights([feature_count, s_1])\n",
    "    w_h2 = init_weights([s_1, s_2])\n",
    "    w_o = init_weights([s_2, nb_classes])\n",
    "    \n",
    "    b = tf.Variable(tf.random_normal([s_1]))\n",
    "    b2 = tf.Variable(tf.random_normal([s_2]))\n",
    "    b_o = tf.Variable(tf.random_normal([nb_classes]))\n",
    "    \n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h) + b)\n",
    "    h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    h2 = tf.nn.relu(tf.matmul(h, w_h2) + b2)\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    \n",
    "    \n",
    "    return tf.matmul(h2, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_keep_input = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 85) (25010, 1)\n",
      "(1000000, 85) (1000000, 1)\n",
      "(?, 85) (?, 1)\n",
      "Step:     0\tLoss: 4.565\tAcc: 42.80%\n",
      "Step:  1000\tLoss: 0.927\tAcc: 55.37%\n",
      "Step:  2000\tLoss: 0.928\tAcc: 55.36%\n",
      "Step:  3000\tLoss: 0.928\tAcc: 55.41%\n",
      "Step:  4000\tLoss: 0.925\tAcc: 55.29%\n",
      "Step:  5000\tLoss: 0.931\tAcc: 54.95%\n",
      "(1000000,)\n",
      "Test Accuracy: 0.870069\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_i = 0.8\n",
    "training_dropout_h = 0.7\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, \n",
    "                                                         p_keep_input: 1.0,\n",
    "                                                         p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5002,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQvRy0BRmahsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ee15f0b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
