{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is z-score that value minus mean divided by standard deviation\n",
    "# http://duramecho.com/Misc/WhyMinusOneInSd.html\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    # 아래꺼 np.c_만 하면 되는거 아닌가? reshape는 왜하지\n",
    "    f = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1])\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep=',', header=None)\n",
    "    return df\n",
    "\n",
    "def merge_column(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(df.shape[1]/2):\n",
    "        new_df[i] = df[i] * df[i+1]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1   2   3   4   5   6   7   8   9   10\n",
      "25005   3   9   2   6   4  11   4  12   2   4   0\n",
      "25006   4   1   4  10   3  13   3   4   1  10   1\n",
      "25007   2   1   2  10   4   4   4   1   4  13   1\n",
      "25008   2  12   4   3   1  10   1  12   4   9   1\n",
      "25009   1   7   3  11   3   3   4   8   3   7   1\n",
      "        0   1   2   3   4   5   6   7   8   9   10\n",
      "999995   3   1   1  12   2   9   4   9   2   6   1\n",
      "999996   3   3   4   5   2   7   1   4   4   3   1\n",
      "999997   1  11   4   7   3   9   1  13   2   7   1\n",
      "999998   3  11   1   8   1   1   3  13   2   8   1\n",
      "999999   2   5   2   9   4   9   2   3   3   3   2\n"
     ]
    }
   ],
   "source": [
    "df = read_data('poker-hand-training-true.data')\n",
    "df_test = read_data('poker-hand-testing.data')\n",
    "print(df.tail())\n",
    "print(df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.24653454  14.06103538   1.25836179  14.19009001   1.26146106\n",
      "  14.02483064   1.24547499  14.04111337   1.25156226  13.99941097]\n",
      "(25010, 10) (25010, 1)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, :-1].values\n",
    "labels = df.iloc[:, -1:].values\n",
    "print(stats.describe(features).variance)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "features_test = df_test.iloc[:, :-1].values\n",
    "labels_test = df_test.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00003999  1.00003999  1.00003999  1.00003999  1.00003999  1.00003999\n",
      "  1.00003999  1.00003999  1.00003999  1.00003999]\n",
      "[ 1.000001  1.000001  1.000001  1.000001  1.000001  1.000001  1.000001\n",
      "  1.000001  1.000001  1.000001]\n"
     ]
    }
   ],
   "source": [
    "features = feature_normalize(features)\n",
    "print(stats.describe(features).variance)\n",
    "\n",
    "features_test = feature_normalize(features_test)\n",
    "print(stats.describe(features_test).variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1\n"
     ]
    }
   ],
   "source": [
    "train_x = features\n",
    "train_y = labels\n",
    "test_x = features_test\n",
    "test_y = labels_test\n",
    "\n",
    "feature_count = train_x.shape[1]\n",
    "label_count = train_y.shape[1]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot_14:0\", shape=(?, 1, 10), dtype=float32)\n",
      "reshape Tensor(\"Reshape_56:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 3000\n",
    "learning_rate = 0.1\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 10\n",
    "\n",
    "# x는 float32 로 할 필요가 있나? normalized 되었기때문에 float32 써야함\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.int32,[None,label_count])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1))\n",
    "\n",
    "def model(X, p_keep_input, p_keep_hidden): # this network is the same as the previous one except with an extra hidden layer + dropout\n",
    "    s_1 = feature_count + 2\n",
    "    s_2 = feature_count + 2\n",
    "    s_3 = feature_count\n",
    "    s_4 = feature_count\n",
    "    s_5 = feature_count\n",
    "    \n",
    "    w_h = init_weights([feature_count, s_1])\n",
    "    w_h2 = init_weights([s_1, s_2])\n",
    "#     w_h3 = init_weights([s_2, s_3])\n",
    "#     w_h4 = init_weights([s_3, s_4])\n",
    "    w_o = init_weights([s_2, nb_classes])\n",
    "    \n",
    "    b = tf.Variable(tf.random_normal([s_1]))\n",
    "    b2 = tf.Variable(tf.random_normal([s_2]))\n",
    "#     b3 = tf.Variable(tf.random_normal([s_3]))\n",
    "    b_o = tf.Variable(tf.random_normal([nb_classes]))\n",
    "    \n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h) + b)\n",
    "    h = tf.nn.dropout(h, p_keep_hidden)\n",
    "    h2 = tf.nn.relu(tf.matmul(h, w_h2) + b2)\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "#     h3 = tf.nn.relu(tf.matmul(h2, w_h3) + b3)\n",
    "#     h3 = tf.nn.dropout(h3, p_keep_hidden)\n",
    "    \n",
    "#     b4 = tf.Variable(tf.random_normal([s_4]))\n",
    "#     h4 = tf.nn.softmax(tf.matmul(h3, w_h4) + b4)\n",
    "    \n",
    "#     h4 = tf.nn.dropout(h4, p_keep_hidden)\n",
    "#     b5 = tf.Variable(tf.random_normal([s_5]))\n",
    "#     w_h5 = init_weights([s_4, s_5])\n",
    "#     h5 = tf.nn.softmax(tf.matmul(h4, w_h5) + b5)\n",
    "    \n",
    "# #     h5 = tf.nn.dropout(h5, p_keep_hidden)\n",
    "#     b6 = tf.Variable(tf.random_normal([feature_count]))\n",
    "#     w_h6 = init_weights([feature_count, feature_count])\n",
    "#     h6 = tf.nn.relu(tf.matmul(h5, w_h6) + b6)\n",
    "    \n",
    "# #     h6 = tf.nn.dropout(h4, p_keep_hidden)\n",
    "#     b7 = tf.Variable(tf.random_normal([feature_count]))\n",
    "#     w_h7 = init_weights([feature_count, feature_count])\n",
    "#     h7 = tf.nn.relu(tf.matmul(h6, w_h7) + b7)\n",
    "    \n",
    "# #     h7 = tf.nn.dropout(h7, p_keep_hidden)\n",
    "#     b8 = tf.Variable(tf.random_normal([feature_count]))\n",
    "#     w_h8 = init_weights([feature_count, feature_count])\n",
    "#     h8 = tf.nn.relu(tf.matmul(h7, w_h8) + b8)\n",
    "    \n",
    "# #     h8 = tf.nn.dropout(h8, p_keep_hidden)\n",
    "#     b9 = tf.Variable(tf.random_normal([feature_count]))\n",
    "#     w_h9 = init_weights([feature_count, feature_count])\n",
    "#     h9 = tf.nn.relu(tf.matmul(h8, w_h9) + b9)\n",
    "    \n",
    "# #     h9 = tf.nn.dropout(h9, p_keep_hidden)\n",
    "#     b10 = tf.Variable(tf.random_normal([feature_count]))\n",
    "#     w_h10 = init_weights([feature_count, feature_count])\n",
    "#     h10 = tf.nn.relu(tf.matmul(h9, w_h10) + b10)\n",
    "    \n",
    "#     h10 = tf.nn.dropout(h10, p_keep_hidden)\n",
    "\n",
    "    \n",
    "    \n",
    "    return tf.matmul(h2, w_o) + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w0, b0, h0 = get_class_logits()\n",
    "\n",
    "p_keep_input = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "h0 = model(X, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/carpedm20/DCGAN-tensorflow/issues/99\n",
    "# all_logits = tf.concat([h0, h1, h2], 1)\n",
    "\n",
    "# regularizers = tf.nn.l2_loss(w0)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h0, labels=Y_one_hot))\n",
    "# + 1e-4*regularizers\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(h0, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 10) (25010, 1)\n",
      "(1000000, 10) (1000000, 1)\n",
      "(?, 10) (?, 1)\n",
      "Step:     0\tLoss: 2.758\tAcc: 0.02%\n",
      "Step:   100\tLoss: 0.950\tAcc: 54.73%\n",
      "Step:   200\tLoss: 0.939\tAcc: 55.22%\n",
      "Step:   300\tLoss: 0.930\tAcc: 55.78%\n",
      "Step:   400\tLoss: 0.909\tAcc: 57.92%\n",
      "Step:   500\tLoss: 0.890\tAcc: 58.42%\n",
      "Step:   600\tLoss: 0.895\tAcc: 56.53%\n",
      "Step:   700\tLoss: 0.880\tAcc: 59.19%\n",
      "Step:   800\tLoss: 0.875\tAcc: 59.51%\n",
      "Step:   900\tLoss: 0.868\tAcc: 59.91%\n",
      "Step:  1000\tLoss: 0.995\tAcc: 54.17%\n",
      "Step:  1100\tLoss: 0.893\tAcc: 58.28%\n",
      "Step:  1200\tLoss: 0.890\tAcc: 58.28%\n",
      "Step:  1300\tLoss: 0.884\tAcc: 58.90%\n",
      "Step:  1400\tLoss: 0.860\tAcc: 60.88%\n",
      "Step:  1500\tLoss: 0.845\tAcc: 61.05%\n",
      "Step:  1600\tLoss: 0.840\tAcc: 61.70%\n",
      "Step:  1700\tLoss: 0.839\tAcc: 61.60%\n",
      "Step:  1800\tLoss: 0.837\tAcc: 61.66%\n",
      "Step:  1900\tLoss: 0.836\tAcc: 61.89%\n",
      "Step:  2000\tLoss: 0.833\tAcc: 62.14%\n",
      "Step:  2100\tLoss: 0.832\tAcc: 62.24%\n",
      "Step:  2200\tLoss: 0.832\tAcc: 62.27%\n",
      "Step:  2300\tLoss: 0.831\tAcc: 62.36%\n",
      "Step:  2400\tLoss: 0.830\tAcc: 62.44%\n",
      "Step:  2500\tLoss: 0.837\tAcc: 61.40%\n",
      "Step:  2600\tLoss: 0.830\tAcc: 62.42%\n",
      "Step:  2700\tLoss: 0.830\tAcc: 62.40%\n",
      "Step:  2800\tLoss: 0.832\tAcc: 62.07%\n",
      "Step:  2900\tLoss: 0.830\tAcc: 62.32%\n",
      "Step:  3000\tLoss: 0.829\tAcc: 62.28%\n",
      "(1000000,)\n",
      "Test Accuracy: 0.616436\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(X.shape, Y.shape)\n",
    "training_dropout_i = 1.0\n",
    "training_dropout_h = 1.0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y, p_keep_input: training_dropout_i, p_keep_hidden: training_dropout_h})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    pre = tf.argmax(h0, 1)\n",
    "    test_yy = np.transpose(test_y.ravel())\n",
    "    print(test_yy.shape)\n",
    "    correct_prediction = tf.equal(pre, test_yy)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_x, \n",
    "                                                         p_keep_input: 1.0,\n",
    "                                                         p_keep_hidden: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3002,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c165fbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_history.shape)\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
