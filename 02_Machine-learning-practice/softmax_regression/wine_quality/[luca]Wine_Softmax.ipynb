{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is z-score that value minus mean divided by standard deviation\n",
    "# http://duramecho.com/Misc/WhyMinusOneInSd.html\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    # 아래꺼 np.c_만 하면 되는거 아닌가? reshape는 왜하지\n",
    "    f = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1])\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genfromtxt가 왜 tuple의 1 d array로만 나오는가?\n",
    "# https://stackoverflow.com/questions/9534408/numpy-genfromtxt-produces-array-of-what-looks-like-tuples-not-a-2d-array-why\n",
    "def read_dataset():\n",
    "    xy = genfromtxt('winequality-red.csv', delimiter=';', skip_header=1, dtype=None)\n",
    "    print xy, xy.shape\n",
    "    x_data = np.array(xy[:, 0:-1])\n",
    "    y_data = np.array(xy[:, [-1]])\n",
    "    return x_data, y_data\n",
    "\n",
    "# np.loadtxt를 쓰자\n",
    "def read_red_wine_data():\n",
    "    xy = np.loadtxt('winequality-red.csv', delimiter=';', skiprows=1)\n",
    "    x_data = xy[:, 0:-1]\n",
    "    y_data = xy[:, [-1]]\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11) (1599, 1)\n",
      "[  3.03141639e+00   3.20623777e-02   3.79474831e-02   1.98789713e+00\n",
      "   2.21514265e-03   1.09414884e+02   1.08210237e+03   3.56202945e-06\n",
      "   2.38351805e-02   2.87326161e-02   1.13564740e+00]\n"
     ]
    }
   ],
   "source": [
    "features, labels = read_red_wine_data()\n",
    "print features.shape, labels.shape\n",
    "print stats.describe(features).variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00062578  1.00062578  1.00062578  1.00062578  1.00062578  1.00062578\n",
      "  1.00062578  1.00062578  1.00062578  1.00062578  1.00062578]\n"
     ]
    }
   ],
   "source": [
    "normalized_features = feature_normalize(features)\n",
    "print stats.describe(normalized_features).variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f, l = append_bias_reshape(normalized_features,labels)\n",
    "n_dim = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rand는 [0,1)의 array를 만들어냄 따라서 0.8보다 작은 행을 true로 만들어 train data set으로 선택하려는 것\n",
    "# 80%를 의미하는 지는 rand 내부를 봐야함\n",
    "rnd_indices = np.random.rand(len(features)) < 0.80\n",
    "\n",
    "train_x = normalized_features[rnd_indices]\n",
    "train_y = labels[rnd_indices]\n",
    "test_x = normalized_features[~rnd_indices]\n",
    "test_y = labels[~rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one_hot', <tf.Tensor 'one_hot_1:0' shape=(?, 1, 11) dtype=float32>)\n",
      "('reshape', <tf.Tensor 'Reshape_4:0' shape=(?, 11) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "nb_classes = 11  # 0 ~ 10\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.int32,[None,1])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W = tf.Variable(tf.ones([n_dim,1]))\n",
    "W = tf.Variable(tf.random_normal([n_dim, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "#init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_ = tf.matmul(X, W)\n",
    "# cost = tf.reduce_mean(tf.square(y_ - Y))\n",
    "\n",
    "# training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "# logits에는 hypothesis랑 logits 중 어느걸 넣어야되고 차이는 뭘까?\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis,\n",
    "                                                 labels=Y_one_hot)\n",
    "\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 2.439\tAcc: 6.39%\n",
      "Step:  1000\tLoss: 1.920\tAcc: 63.93%\n",
      "Step:  2000\tLoss: 1.909\tAcc: 64.40%\n",
      "Step:  3000\tLoss: 1.904\tAcc: 64.64%\n",
      "Step:  4000\tLoss: 1.901\tAcc: 64.88%\n",
      "Step:  5000\tLoss: 1.895\tAcc: 65.51%\n",
      "Step:  6000\tLoss: 1.892\tAcc: 65.75%\n",
      "Step:  7000\tLoss: 1.891\tAcc: 65.90%\n",
      "Step:  8000\tLoss: 1.889\tAcc: 65.90%\n",
      "Step:  9000\tLoss: 1.888\tAcc: 65.98%\n",
      "Step: 10000\tLoss: 1.887\tAcc: 65.98%\n",
      "('Accuracy:', 0.37168571)\n",
      "[['1.20671248436' '1.22706711292' '0.987164080143' '1.8101348877'\n",
      "  '-23.9491405487' '-13.9522438049' '9.9496307373' '29.1473770142'\n",
      "  '0.655552625656' '1.20251882076' '0.22347278893' '1 - fixed acidity']\n",
      " ['-1.90141379833' '-1.66354858875' '-1.81717050076' '-1.08203494549'\n",
      "  '18.5013256073' '15.723938942' '-16.2419548035' '-27.8620700836'\n",
      "  '-0.628006577492' '-1.09566819668' '-0.378148019314'\n",
      "  '2 - volatile acidity']\n",
      " ['0.11244533211' '0.470645219088' '0.234025537968' '0.591533184052'\n",
      "  '4.1648812294' '11.708325386' '-12.3225345612' '-8.24929523468'\n",
      "  '0.730527698994' '0.731104254723' '0.428788870573' '3 - citric acid']\n",
      " ['-0.50834941864' '-0.942539334297' '-1.42203807831' '-1.02322590351'\n",
      "  '8.45301151276' '4.05888271332' '-14.7719974518' '22.038444519'\n",
      "  '-0.876211702824' '-0.29164865613' '-1.21819710732' '4 - residual sugar']\n",
      " ['1.3020414114' '0.441458910704' '0.354598611593' '0.794421315193'\n",
      "  '-2.43523430824' '9.51833629608' '-2.02949047089' '-10.5351676941'\n",
      "  '0.852988779545' '1.97302246094' '1.58164322376' '5 - chlorides']\n",
      " ['0.309087097645' '0.434660047293' '0.424375206232' '-0.111375905573'\n",
      "  '10.7394618988' '3.72184586525' '-1.58657467365' '-12.4395856857'\n",
      "  '-0.042758770287' '-0.124013803899' '0.318403571844'\n",
      "  '6 - free sulfur dioxide']\n",
      " ['-1.01257419586' '-3.49911427498' '-4.13742017746' '-1.27856528759'\n",
      "  '-9.87107276917' '12.4452981949' '-14.1534481049' '-32.6536827087'\n",
      "  '-1.38703870773' '-1.27547740936' '-1.94031631947'\n",
      "  '7 - total sulfur dioxide']\n",
      " ['0.221289843321' '0.064948707819' '0.552872776985' '0.702974140644'\n",
      "  '1.63670265675' '-5.83282613754' '14.3273000717' '-14.8474311829'\n",
      "  '0.321955919266' '-0.132593721151' '1.38470613956' '8 - density']\n",
      " ['0.400562703609' '0.372347444296' '0.174738675356' '0.454993486404'\n",
      "  '-13.9711341858' '-6.30028820038' '5.74760055542' '0.704814732075'\n",
      "  '-0.222715631127' '0.342197775841' '-0.313229620457' '9 - pH']\n",
      " ['-1.82538986206' '-0.542257845402' '-0.584852397442' '-1.67908418179'\n",
      "  '-5.88218164444' '-17.8130550385' '7.28275966644' '24.5489730835'\n",
      "  '-2.41458821297' '-2.13917207718' '-2.62685322762' '10 - sulphates']\n",
      " ['-0.424953043461' '-0.115885987878' '0.264101654291' '0.22506660223'\n",
      "  '1.52173447609' '-37.4900436401' '25.4472141266' '38.6492042542'\n",
      "  '-0.997543215752' '-0.316491246223' '-0.266031354666' '11 - alcohol']]\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "\n",
    "# for epoch in range(training_epochs):\n",
    "#     sess.run(training_step,feed_dict={X:train_x,Y:train_y})\n",
    "#     cost_history = np.append(cost_history,sess.run(cost,feed_dict={X: train_x,Y: train_y}))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train_x, Y: train_y})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                                 X: train_x, Y: train_y})\n",
    "        cost_history = np.append(cost_history, acc)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    # Test model and check accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), train_y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={X: train_x}))\n",
    "    \n",
    "    col_desc = [\n",
    "    \"1 - fixed acidity\",\n",
    "    \"2 - volatile acidity\",\n",
    "    \"3 - citric acid\",\n",
    "    \"4 - residual sugar\",\n",
    "    \"5 - chlorides\",\n",
    "    \"6 - free sulfur dioxide\",\n",
    "    \"7 - total sulfur dioxide\",\n",
    "    \"8 - density\",\n",
    "    \"9 - pH\",\n",
    "    \"10 - sulphates\",\n",
    "    \"11 - alcohol\"]\n",
    "\n",
    "    print np.c_[sess.run(W), col_desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10002,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nocp2D8YYwdIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33e7132290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print cost_history.shape\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
