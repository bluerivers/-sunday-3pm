# 8/28 ML 스터디 시즌 3 1주 차


## 진행사항

* kaggle + MNIST 를 통해 kaggle 시스템에 익숙해지기
* kaggle kernel
    * Gin

## 차주 준비사항

* CNN으로 MNIST 풀고 kaggle에 제출
* 다른 문제 정해서 오기

### 각자 깨달은 점

#### Luca

#### Gin

* 실습을 진행하면서 CNN 자체에 대한 궁금증이 생겨서 CNN에 대해 찾아봤고 직접적으로 코드와 매칭하면서 이해가 더 잘 되게 됐다. 논문 자체를 볼필요는 없지만 왜 이런 방법을 쓰는 지를 이해하면 좀더 유용하게 사용할 수 있을 듯 하다.
* 정확도를 올리는 것도 해야 하지만 이렇게 구한 weight를 가지고 application으로 만드는 과정을 진행해보면 어떨까? 이것이 되고 나면 스스로 데이터를 모으는 것을 정의해보면 ML을 위한 적용 chain 이 완성할 수 있을 것으로 보인다.
* 참고자료
    * "CNN의 핵심 아이디어는 preprocessing이 실제 performance에 크게 영향을 미치니까, 아예 이 preprocessing을 가장 잘해주는, 가장 좋은 feature map을 뽑아주는 convolution filter를 learning하는 모델을 만들어버리자는 것이다." - http://sanghyukchun.github.io/75/


#### Brad

#### Jay
